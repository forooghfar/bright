{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 9s 146ms/step - loss: 0.2980 - accuracy: 0.9146 - val_loss: 0.1695 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0841 - accuracy: 0.9905 - val_loss: 0.2804 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1075 - accuracy: 0.9905 - val_loss: 0.3005 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0732 - accuracy: 0.9905 - val_loss: 0.2791 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0739 - accuracy: 0.9905 - val_loss: 0.2365 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0665 - accuracy: 0.9905 - val_loss: 0.2160 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0558 - accuracy: 0.9905 - val_loss: 0.2112 - val_accuracy: 0.9620 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0706 - accuracy: 0.9905 - val_loss: 0.2086 - val_accuracy: 0.9620 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0683 - accuracy: 0.9905 - val_loss: 0.2076 - val_accuracy: 0.9620 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0606 - accuracy: 0.9905 - val_loss: 0.1938 - val_accuracy: 0.9620 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0709 - accuracy: 0.9905 - val_loss: 0.1864 - val_accuracy: 0.9620 - lr: 5.0000e-04\n",
      "Train Accuracy: 99.05%\n",
      "Test Accuracy: 96.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\class_python_madrese\\repl\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# model.py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# بارگذاری و پیش‌پردازش داده‌ها\n",
    "# current_dir = os.path.dirname(__file__)  # پوشه فعلی که model_tark.py در آن قرار دارد\n",
    "csv_path = os.path.join( 'student_math.csv') \n",
    "\n",
    "df = pd.read_csv('student_math.csv', sep=';', engine='python')\n",
    "\n",
    "\n",
    "df['attendance_rate'] = 100 - (df['absences'] / df['absences'].max() * 100)\n",
    "df['average_grade'] = df[['G1', 'G2', 'G3']].mean(axis=1)\n",
    "df['disciplinary_actions'] = df['failures']\n",
    "df['extracurricular_participation'] = df['activities'].map({'no': 0, 'yes': 1})\n",
    "df['gender'] = df['sex'].map({'F': 0, 'M': 1})\n",
    "df['economic_status'] = df[['Medu', 'Fedu']].mean(axis=1)\n",
    "df['parental_support'] = df['famsup'].map({'no': 0, 'yes': 1})\n",
    "# تعریف قاعده‌ای برای تعیین `dropped_out`\n",
    "df['dropped_out'] = (\n",
    "    (df['attendance_rate'] < 75) |                # حضور کمتر از 75%\n",
    "    (df['average_grade'] < 12) |                  # میانگین نمرات کمتر از 12\n",
    "    (df['disciplinary_actions'] > 2) |            # بیشتر از 2 اقدام انضباطی\n",
    "    (df['parental_support'] == 0) |               # عدم حمایت والدین\n",
    "    (df['economic_status'] < 2) |                 # وضعیت اقتصادی ضعیف\n",
    "    (df['age'] > 15) |                            # سن بیشتر از 18\n",
    "    (df['gender'] == 1)                           # جنسیت مذکر\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "features = ['attendance_rate', 'average_grade', 'disciplinary_actions', 'extracurricular_participation', \n",
    "            'age', 'gender', 'economic_status', 'parental_support']\n",
    "\n",
    "\n",
    "# تعریف ویژگی‌ها و هدف\n",
    "X = df[['attendance_rate', 'average_grade', 'disciplinary_actions', 'extracurricular_participation', \n",
    "        'age', 'gender', 'economic_status', 'parental_support']]\n",
    "y = df['dropped_out']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# تقسیم داده‌ها به مجموعه آموزش و تست\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# تعریف و اعمال مقیاس‌کننده\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# تغییر شکل داده‌ها برای استفاده در LSTM\n",
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# ذخیره مقادیر میانگین و انحراف معیار برای استفاده در آینده\n",
    "np.save('scaler.npy', scaler.mean_)\n",
    "np.save('scaler_scale.npy', scaler.scale_)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# کامپایل و آموزش مدل با استفاده از EarlyStopping و ReduceLROnPlateau\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# ارزیابی مدل\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# # تعریف مدل\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # کامپایل کردن مدل\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # آموزش مدل\n",
    "# model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# تابع ذخیره‌سازی مدل و مقیاس‌کننده\n",
    "model.save('dropout_model.h5')\n",
    "#ذخیره دقت\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "np.save('train_accuracy.npy', train_accuracy)\n",
    "np.save('test_accuracy.npy', test_accuracy)\n",
    "\n",
    "def predict_dropout(X_new):\n",
    "    # Load scaler and model\n",
    "    scaler_mean = np.load('scaler.npy')\n",
    "    scaler_scale = np.load('scaler_scale.npy')\n",
    "    X_new = (X_new - scaler_mean) / scaler_scale\n",
    "    X_new = X_new.reshape((X_new.shape[0], 1, X_new.shape[1]))\n",
    "    prediction = model.predict(X_new)[0][0]\n",
    "    return prediction * 100\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
